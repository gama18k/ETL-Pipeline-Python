# Projeto de ETL com Python

Este repositÃ³rio contÃ©m um projeto simples de ETL (Extract, Transform, Load) implementado em Python, utilizando dados de duas empresas fictÃ­cias em formatos diferentes (JSON e CSV). O objetivo Ã© consolidar essas informaÃ§Ãµes em um Ãºnico dataset padronizado.

## ğŸ“ Estrutura do Projeto

â”œâ”€â”€ data_raw/                # Dados brutos (input)
â”‚   â”œâ”€â”€ dados_empresaA.json
â”‚   â””â”€â”€ dados_empresaB.csv
â”œâ”€â”€ data_processed/          # Dados transformados (output)
â”‚   â””â”€â”€ dados_combinados.csv
â”œâ”€â”€ pipeline_versao_classemetodo.py  # Pipeline usando mÃ©todo de classe
â”œâ”€â”€ pipeline_versao_instancia.py      # Pipeline usando instÃ¢ncia direta
â”œâ”€â”€ dados_modelo_classemetodo.py      # Classe Dados com @classmethod
â””â”€â”€ dados_modelo_instancia.py          # Classe Dados com suporte a lista e leitura flexÃ­vel



## âš™ï¸ Funcionalidades

- Leitura de arquivos JSON e CSV.
- PadronizaÃ§Ã£o de colunas entre diferentes fontes de dados.
- JunÃ§Ã£o dos dados em uma Ãºnica estrutura unificada.
- Salvamento dos dados finais em formato `.csv`.

## ğŸ§  LÃ³gica do ETL

### Extract
Os dados sÃ£o lidos dos arquivos localizados em `data_raw/`, utilizando diferentes estratÃ©gias de leitura (mÃ©todos de classe ou instÃ¢ncia).

### Transform
A padronizaÃ§Ã£o Ã© feita com base em um mapeamento de colunas da empresa B para igualar o formato da empresa A.

### Load
Os dados consolidados sÃ£o salvos em `data_processed/dados_combinados.csv`.

## ğŸ Requisitos

- Python 3.7+
- Nenhuma biblioteca externa Ã© necessÃ¡ria (usa apenas `json` e `csv`).

## ğŸ“Œ ObservaÃ§Ãµes

Duas implementaÃ§Ãµes diferentes da classe `Dados` foram criadas:
- Uma com mÃ©todos estÃ¡ticos e de classe.
- Outra com leitura direta via instÃ¢ncia e suporte a dados em memÃ³ria (`list`).

